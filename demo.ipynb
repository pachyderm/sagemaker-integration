{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pachyderm - AWS Sagemaker Integration: Automatically Train ML Models on Version Controlled Datasets\n",
        "\n",
        "> This project was created by [Winder Research, an ML consultancy](https://WinderResearch.com), and funded by [Pachyderm](https://pachyderm.com).\n",
        "\n",
        "[Pachyderm](https://pachyderm.com) is a data science platform that combines data lineage with end-to-end pipelines.\n",
        "Its data versioninig feature allows you to inspect, diff and rollback commits with a single line of code.\n",
        "[AWS Sagemaker](https://aws.amazon.com/sagemaker/) is a managed ML platform to create, train, and deploy machine-learning models in the cloud. \n",
        "Sagemaker ships with powerful pre-packaged ML models that you can train without taking care of the infrastructure; the resource provisioning is all taken care of, all you have to do is select the machine type.\n",
        "\n",
        "\n",
        "\n",
        "This notebook shows an example integration of Pachyderm and AWS Sagemaker to train a machine-learning model for customer churn prediction.\n",
        "Customer churn is costly to many businesses but with ML you can possibly identify unhappy customers early on and offer them an incentive to stay.\n",
        "In this example, I use a historical dataset comprising of demographics and usage records (e.g. calls/day, night calls, etc.) to predict whether a customer is going to churn.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The purpose of this demo is to show how Pachyderm can be used in concert with Sagemaker to train a model in the cloud and version control your artifacts (i.e. training data, trained model & metadata).\n",
        "Therefore, I'll demonstrate the sufficient Pachyderm work needed to fit a model in Sagemaker; a similar workflow would apply for other Sagemaker features such as model deployment or data processing."
      ],
      "metadata": {},
      "id": "8cc46a89-480e-4e90-852a-a11138b35e0a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "Both Pachyderm Hub and Sagemaker are managed services so all you need to install is their respective clients:\n",
        "\n",
        "* A [Pachyderm client](https://docs.pachyderm.com/latest/getting_started/local_installation/#install-pachctl) (i.e. `pachctl`) installed on your local machine\n",
        "* A workspace on [Pachyderm Hub](https://hub.pachyderm.com/); follow their instructions to authenticate `pachctl`\n",
        "* An AWS account with an execution role attached comprising of the `AmazonSageMakerFullAccess` policy\n",
        "* A [AWS Command Line Interface V2](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html) installed and [configured with your AWS key ID](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-creds)\n",
        "* Python to run this notebook\n",
        "\n",
        "Now, let us set up some configuration that will be used througout the notebook."
      ],
      "metadata": {},
      "id": "8f1db5a0-5759-4aed-8622-327a5e6fa3b9"
    },
    {
      "cell_type": "code",
      "source": [
        "BUCKET_NAME = \"sagemaker-SOME_BUCKET_NAME\" # make sure the `sagemaker` substring is included in the bucket name\n",
        "AWS_BUCKET = \"s3://\" + BUCKET_NAME\n",
        "AWS_REGION = \"us-west-2\" # bucket and Sagemaker instance must reside in the same region\n",
        "AWS_ACCESS_KEY_ID = \"YOUR_AWS_KEY_ID\"\n",
        "AWS_ACCESS_SECRET_KEY = \"YOUR_AWS_SECRET_KEY\"\n",
        "AWS_SAGEMAKER_ROLE = \"arn:aws:iam::xxxxxxxxxxxx:role/SageMaker-EMR-ExecutionRole\""
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {},
      "id": "8f2a4c8f-e735-41a6-aa9b-368187f6604a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check Pachyderm cluster"
      ],
      "metadata": {},
      "id": "98fcde14-9ce6-4700-a98d-071db74abc7b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl version"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPONENT           VERSION             \n",
            "pachctl             1.13.3              \n",
            "pachd               1.12.5              \n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {},
      "id": "3b92293f-368b-444c-a5ca-58ff0f9074ab"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access Pachyderm dashboard, head to https://hub.pachyderm.com/ and click on the meatballs menu (three horizontal dots) on the workspace list."
      ],
      "metadata": {},
      "id": "21d36d84-d11c-41f3-9450-805c25b49d88"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Training Data\n",
        "\n",
        "Below I create a training data repository and populate it with the publicly available customer churn dataset used in [this tutorial](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.html); it's attributed to the University of California Irvine Repository of Machine Learning Datasets and contains features like State, Area Code, Day Calls, Intl Calls, etc.\n",
        "For the sake of brevity, I have pre-processed the dataset with dummy encoding for the categorical features."
      ],
      "metadata": {},
      "id": "b39c6c2e-8052-427d-894e-f8bc9f1c309e"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl create repo churn_dataset"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {},
      "id": "c2435138-98b1-4973-8258-166680243c65"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl list repo"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME          CREATED                SIZE (MASTER) ACCESS LEVEL \n",
            "churn_dataset Less than a second ago 0B            OWNER         \n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {},
      "id": "b77709c1-fde8-4347-8a7a-8bb028f6284b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of training a ML model usually involves using two datasets, one for fitting the actual model weights (`train.csv`) and one for driving the training run accross hyperparameter tuning, reducing bias, etc. (`validation.csv`)."
      ],
      "metadata": {},
      "id": "8ef0c7a1-cb2d-4d1b-a3b3-b7d65593eae5"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl put file churn_dataset@master:train.csv -f dataset/train.csv\n",
        "!pachctl put file churn_dataset@master:validation.csv -f dataset/validation.csv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/train.csv 943.50KB / 943.50 KB [===========================] 0s 0.00 b/s\n",
            "dataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n",
            "\u001b[1A\u001b[Jdataset/validation.csv 269.54KB / 269.54 KB [======================] 0s 0.00 b/s\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "bc632bf8-c231-4944-8ee1-383e0fd30d11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pipeline: Copy Churn Data from Pachyderm to AWS S3"
      ],
      "metadata": {},
      "id": "7713c5a0-47c4-46c4-b2e7-44dac831b1a2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create a pipeline to copy my churn dataset from Pachyderm to AWS so that Sagemaker can use it.\n",
        "Firstly I make an AWS bucket (name must contain `sagemaker`) in the same region I use for Sagemaker, then I build a simple pipeline to copy the content of `churn_dataset` repo to the target AWS bucket.\n",
        "\n",
        "### Important\n",
        "\n",
        "This pipeline could be simplified by using the [`egress` pipeline option](https://docs.pachyderm.com/latest/how-tos/basic-data-operations/export-data-out-pachyderm/export-data-egress/). \n",
        "I'd just copy data from `/pfs/churn_dataset/` to `/pfs/out/` and Pachyderm takes care of pushing it to AWS S3.\n",
        "However, `egress` requires a credentials setup that's not exposed in Pachyderm Hub so for the time being it's not viable."
      ],
      "metadata": {},
      "id": "9f23e776-7305-421c-b16c-27a4cb17534c"
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 mb {AWS_BUCKET} --region {AWS_DEFAULT_REGION}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make_bucket: sagemaker-enrico-test-xxx123\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {},
      "id": "c7809e77-f08f-4238-8b74-c3dbcacd8cb1"
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = \"\"\"\n",
        "{\n",
        "  \"pipeline\": {\n",
        "    \"name\": \"copy_to_s3\"\n",
        "  },\n",
        "  \"description\": \"Copy training data to AWS.\",\n",
        "  \"transform\": {\n",
        "    \"image\": \"winderresearch/example-pachyderm-copy-to-aws-s3:0.0.1\",\n",
        "    \"cmd\": [\"/bin/bash\"],\n",
        "    \"stdin\": [\n",
        "        \"python -u /pach_to_aws.py --target_bucket %s\"\n",
        "    ],\n",
        "    \"env\": {\n",
        "        \"AWS_DEFAULT_REGION\": \"%s\",\n",
        "        \"AWS_ACCESS_KEY_ID\": \"%s\",\n",
        "        \"AWS_SECRET_ACCESS_KEY\": \"%s\"\n",
        "    }\n",
        "  },\n",
        "  \"parallelism_spec\": {\n",
        "    \"constant\": \"1\"\n",
        "  },\n",
        "  \"input\": {\n",
        "    \"pfs\": {\n",
        "      \"repo\": \"churn_dataset\",\n",
        "      \"branch\": \"master\",\n",
        "      \"glob\": \"/\"\n",
        "    }\n",
        "  }\n",
        "}\"\"\" % (BUCKET_NAME, AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "print(pipeline, file=open('copy_to_s3.json', 'w'))"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {},
      "id": "c9b467c7-4686-4c3a-be03-c017fa7f7bd9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl create pipeline -f copy_to_s3.json"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {},
      "id": "4bde9e15-5c0e-474d-8921-28319544940f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl flush commit copy_to_s3@master --raw > /dev/null 2>&1"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {},
      "id": "50291915-809f-42ba-b78a-dc791d59ec38"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl logs --pipeline=copy_to_s3"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {},
      "id": "d97b05fe-4309-4142-b8e1-6d9903fc3313"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify data has been copied to AWS."
      ],
      "metadata": {},
      "id": "5638c2e2-d9c0-4697-9797-ac2faa0572ea"
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls {BUCKET_NAME}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-08-11 11:15:53     943498 train.csv\n",
            "2021-08-11 11:15:54     269544 validation.csv\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {},
      "id": "adc68ac8-c6d7-410e-bb57-395dc640a94d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what the current Pachyderm directed acyclic graph (DAG) looks like:\n",
        "\n",
        "\n",
        "![Screenshot 2021-08-09 at 16.13.48.png](attachment:5f217574-2bca-46fb-aa20-5ee306b8367f.png)\n",
        "\n"
      ],
      "metadata": {},
      "id": "4e51e289-82c3-4097-a410-c541a623d6a0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pipeline: Train a ML Model on Sagemaker\n",
        "\n",
        "Now that I've made the training data available on S3, it's time to create a training pipeline.\n",
        "The pipeline below uses the Sagemaker SDK to create a Sagemaker job that fetches the input data from `BUCKET_NAME`, trains a XGBoost model, and makes the artifacts available in the same bucket.\n",
        "\n",
        "XGBoost is an advanced ensamble decision-tree algorithm that uses extreme gradient boosting to tweak the model weights, for further details check [this article](https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/).\n",
        "\n",
        "### Important \n",
        "\n",
        "Training a model is a time consuming operation and Sagemaker executes it remotly in the AWS cloud.\n",
        "To ensure the pipeline ends only when the training job has completed I must make sure the Sagemaker call is \"blocking\".\n",
        "Thus, in the training script I enforce `wait=True` in `model.fit()`."
      ],
      "metadata": {},
      "id": "f86838b1-e1f0-4db4-99ff-e44c841d4d22"
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = \"\"\"\n",
        "{\n",
        "  \"pipeline\": {\n",
        "    \"name\": \"train_on_sagemaker\"\n",
        "  },\n",
        "  \"reprocess_spec\": \"every_job\",\n",
        "  \"description\": \"Launch a training job on Sagemaker from Pachyderm pipeline\",\n",
        "  \"transform\": {\n",
        "    \"image\": \"winderresearch/example-pachyderm-train-sagemaker:0.0.1\",\n",
        "    \"cmd\": [\"/bin/bash\"],\n",
        "    \"stdin\": [\n",
        "        \"python -u /sage.py --bucket %s --role %s\"\n",
        "    ],\n",
        "    \"env\": {\n",
        "        \"AWS_DEFAULT_REGION\": \"%s\",\n",
        "        \"AWS_ACCESS_KEY_ID\": \"%s\",\n",
        "        \"AWS_SECRET_ACCESS_KEY\": \"%s\"\n",
        "    }\n",
        "  },\n",
        "  \"parallelism_spec\": {\n",
        "    \"constant\": \"1\"\n",
        "  },\n",
        "  \"input\": {\n",
        "    \"pfs\": {\n",
        "      \"repo\": \"copy_to_s3\",\n",
        "      \"branch\": \"master\",\n",
        "      \"glob\": \"/\"\n",
        "    }\n",
        "  }\n",
        "}\"\"\" % (BUCKET_NAME, AWS_SAGEMAKER_ROLE, AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "print(pipeline, file=open('train_on_sagemaker.json', 'w'))"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {},
      "id": "ad09007e-fb7c-4876-a517-3a375253b0b7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl create pipeline -f train_on_sagemaker.json"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {},
      "id": "146e7c88-8f42-479b-aa7c-732fd16d1a5f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl flush commit train_on_sagemaker@master --raw > /dev/null 2>&1"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {},
      "id": "7b0bccbb-7bbe-4b88-889f-d0a24268dc8c"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl logs --pipeline=train_on_sagemaker"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-08-11 09:16:18 Starting - Starting the training job...\n",
            "2021-08-11 09:16:41 Starting - Launching requested ML instancesProfilerReport-1628673378: InProgress\n",
            "......\n",
            "2021-08-11 09:17:42 Starting - Preparing the instances for training.........\n",
            "2021-08-11 09:19:22 Downloading - Downloading input data...\n",
            "2021-08-11 09:19:52 Training - Training image download completed. Training in progress..Arguments: train\n",
            "[2021-08-11:09:19:54:INFO] Running standalone xgboost training.\n",
            "[2021-08-11:09:19:54:INFO] File size need to be processed in the node: 1.16mb. Available memory size in the node: 8417.98mb\n",
            "[2021-08-11:09:19:54:INFO] Determined delimiter of CSV input is ','\n",
            "[09:19:54] S3DistributionType set as FullyReplicated\n",
            "[09:19:54] 3500x99 matrix with 346500 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\n",
            "[2021-08-11:09:19:54:INFO] Determined delimiter of CSV input is ','\n",
            "[09:19:54] S3DistributionType set as FullyReplicated\n",
            "[09:19:54] 1000x99 matrix with 99000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[0]#011train-error:0.116857#011validation-error:0.114\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[1]#011train-error:0.102857#011validation-error:0.1\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[2]#011train-error:0.097714#011validation-error:0.095\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[3]#011train-error:0.091714#011validation-error:0.092\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[4]#011train-error:0.083143#011validation-error:0.083\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[5]#011train-error:0.079714#011validation-error:0.084\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[6]#011train-error:0.077429#011validation-error:0.086\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[7]#011train-error:0.076286#011validation-error:0.08\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[8]#011train-error:0.073143#011validation-error:0.077\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[9]#011train-error:0.072286#011validation-error:0.074\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[10]#011train-error:0.068286#011validation-error:0.076\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[11]#011train-error:0.067143#011validation-error:0.076\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\n",
            "[12]#011train-error:0.066286#011validation-error:0.079\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[13]#011train-error:0.064286#011validation-error:0.079\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\n",
            "[14]#011train-error:0.064571#011validation-error:0.081\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[15]#011train-error:0.063143#011validation-error:0.078\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[16]#011train-error:0.062286#011validation-error:0.073\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[17]#011train-error:0.059714#011validation-error:0.072\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\n",
            "[18]#011train-error:0.059429#011validation-error:0.071\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[19]#011train-error:0.058286#011validation-error:0.071\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[20]#011train-error:0.059714#011validation-error:0.07\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[21]#011train-error:0.058857#011validation-error:0.071\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=5\n",
            "[22]#011train-error:0.058571#011validation-error:0.072\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[23]#011train-error:0.058571#011validation-error:0.069\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[24]#011train-error:0.057143#011validation-error:0.067\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[25]#011train-error:0.051714#011validation-error:0.068\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[26]#011train-error:0.052#011validation-error:0.066\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[27]#011train-error:0.052286#011validation-error:0.065\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=4\n",
            "[28]#011train-error:0.052#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=4\n",
            "[29]#011train-error:0.052286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\n",
            "[30]#011train-error:0.052571#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[31]#011train-error:0.050571#011validation-error:0.065\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[32]#011train-error:0.050286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[33]#011train-error:0.050286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\n",
            "[34]#011train-error:0.050286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\n",
            "[35]#011train-error:0.051143#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[36]#011train-error:0.050286#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=4\n",
            "[37]#011train-error:0.050857#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[38]#011train-error:0.048857#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=3\n",
            "[39]#011train-error:0.049143#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\n",
            "[40]#011train-error:0.048286#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\n",
            "[41]#011train-error:0.047714#011validation-error:0.064\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\n",
            "[42]#011train-error:0.047429#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 24 pruned nodes, max_depth=5\n",
            "[43]#011train-error:0.047714#011validation-error:0.066\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\n",
            "[44]#011train-error:0.046571#011validation-error:0.065\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[45]#011train-error:0.046#011validation-error:0.066\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\n",
            "[46]#011train-error:0.046#011validation-error:0.066\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=4\n",
            "[47]#011train-error:0.046#011validation-error:0.064\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\n",
            "[48]#011train-error:0.045143#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 26 pruned nodes, max_depth=2\n",
            "[49]#011train-error:0.045429#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[50]#011train-error:0.044#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[51]#011train-error:0.044571#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\n",
            "[52]#011train-error:0.044571#011validation-error:0.061\n",
            "[53]#011train-error:0.043714#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\n",
            "[54]#011train-error:0.044#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\n",
            "[55]#011train-error:0.044#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\n",
            "[56]#011train-error:0.043143#011validation-error:0.058\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[57]#011train-error:0.042571#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\n",
            "[58]#011train-error:0.042571#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 22 pruned nodes, max_depth=4\n",
            "[59]#011train-error:0.041714#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\n",
            "[60]#011train-error:0.041714#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\n",
            "[61]#011train-error:0.041714#011validation-error:0.062\n",
            "[62]#011train-error:0.042286#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=4\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[63]#011train-error:0.042857#011validation-error:0.061\n",
            "[64]#011train-error:0.042571#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\n",
            "[65]#011train-error:0.042857#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=4\n",
            "[66]#011train-error:0.041714#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\n",
            "[67]#011train-error:0.041143#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\n",
            "[68]#011train-error:0.041143#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 16 pruned nodes, max_depth=3\n",
            "[69]#011train-error:0.040286#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\n",
            "[70]#011train-error:0.040286#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 28 pruned nodes, max_depth=3\n",
            "[71]#011train-error:0.04#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\n",
            "[72]#011train-error:0.04#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 22 pruned nodes, max_depth=4\n",
            "[73]#011train-error:0.039429#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[74]#011train-error:0.04#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[75]#011train-error:0.039714#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 24 pruned nodes, max_depth=3\n",
            "[76]#011train-error:0.039429#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\n",
            "[77]#011train-error:0.039143#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\n",
            "[78]#011train-error:0.039429#011validation-error:0.06\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\n",
            "[79]#011train-error:0.040286#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 22 pruned nodes, max_depth=4\n",
            "[80]#011train-error:0.039429#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=3\n",
            "[81]#011train-error:0.039143#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\n",
            "[82]#011train-error:0.039143#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\n",
            "[83]#011train-error:0.038857#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\n",
            "[84]#011train-error:0.038286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\n",
            "[85]#011train-error:0.038286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\n",
            "[86]#011train-error:0.037714#011validation-error:0.064\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\n",
            "[87]#011train-error:0.037429#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 18 pruned nodes, max_depth=3\n",
            "[88]#011train-error:0.037714#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[89]#011train-error:0.037714#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\n",
            "[90]#011train-error:0.037714#011validation-error:0.062\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\n",
            "[91]#011train-error:0.037429#011validation-error:0.064\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\n",
            "[92]#011train-error:0.037429#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\n",
            "[93]#011train-error:0.038286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=3\n",
            "[94]#011train-error:0.036286#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\n",
            "[95]#011train-error:0.036286#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\n",
            "[96]#011train-error:0.036571#011validation-error:0.061\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\n",
            "[97]#011train-error:0.036#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\n",
            "[98]#011train-error:0.036286#011validation-error:0.063\n",
            "[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\n",
            "[99]#011train-error:0.036286#011validation-error:0.064\n",
            "\n",
            "2021-08-11 09:20:22 Uploading - Uploading generated training model\n",
            "2021-08-11 09:20:22 Completed - Training job completed\n",
            "Training seconds: 63\n",
            "Billable seconds: 63\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {},
      "id": "e34e3b46-74ac-4ec1-96d1-e7e5dca76f91"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open Sagemaker and reach the `Training / Training jobs` page. \n",
        "Here you check see your job status and inspect it's internals.\n",
        "\n",
        "![Screenshot 2021-08-09 at 16.45.23.png](attachment:b7268f40-838d-4ce5-afe4-0e18c9bf8a82.png)"
      ],
      "metadata": {},
      "id": "6583ec9a-26ec-4b7c-9971-454a66ec60ee"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The run has produced some artifacts, stored on a bucket. Let's list some of them."
      ],
      "metadata": {},
      "id": "5eff7da7-07b2-49da-9f90-d3e9eab68355"
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls --recursive {AWS_BUCKET} | less"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-08-11 11:20:01      47802 output/xgboost-2021-08-11-09-16-18-187/output/mod\u001b[mel.tar.gz\u001b[m\n",
            "2021-08-11 11:20:05          0 output/xgboost-2021-08-11-09-16-18-187/profiler-o\u001b[mutput/framework/training_job_end.ts\u001b[m\n",
            "2021-08-11 11:19:59     215835 output/xgboost-2021-08-11-09-16-18-187/profiler-o\u001b[mutput/system/incremental/2021081109/1628673540.algo-1.json\u001b[m\n",
            "2021-08-11 11:20:05          0 output/xgboost-2021-08-11-09-16-18-187/profiler-o\u001b[mutput/system/training_job_end.ts\u001b[m\n",
            "2021-08-11 11:15:53     943498 train.csv\u001b[m\n",
            "2021-08-11 11:15:54     269544 validation.csv\u001b[m\n",
            "\u001b[K\u001b[7m(END)\u001b[m\u001b[K"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {},
      "id": "738dba16-7a56-4b1c-8b75-7aac335bf1a4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pipeline: Download Trained Model from AWS S3 to Pachyderm\n",
        "\n",
        "At this stage Sagemaker's job has finished but the resulting artifacts are not version controlled yet.\n",
        "With this simple pipeline I pull download the training output into a repository where data lineage is guarateed by Pachyderm."
      ],
      "metadata": {},
      "id": "d49f1026-1b6a-488b-afbb-80a16914274a"
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = \"\"\"\n",
        "{\n",
        "  \"pipeline\": {\n",
        "    \"name\": \"download_from_s3\"\n",
        "  },\n",
        "  \"description\": \"Download training artifacts from AWS S3.\",\n",
        "  \"transform\": {\n",
        "    \"image\": \"winderresearch/example-pachyderm-copy-to-aws-s3:0.0.1\",\n",
        "    \"cmd\": [\"/bin/bash\"],\n",
        "    \"stdin\": [\n",
        "        \"python -u ./aws_to_pach.py --src_bucket %s\"\n",
        "    ],\n",
        "    \"env\": {\n",
        "        \"AWS_DEFAULT_REGION\": \"%s\",\n",
        "        \"AWS_ACCESS_KEY_ID\": \"%s\",\n",
        "        \"AWS_SECRET_ACCESS_KEY\": \"%s\"\n",
        "    }\n",
        "  },\n",
        "  \"parallelism_spec\": {\n",
        "    \"constant\": \"1\"\n",
        "  },\n",
        "  \"input\": {\n",
        "    \"pfs\": {\n",
        "      \"repo\": \"train_on_sagemaker\",\n",
        "      \"branch\": \"master\",\n",
        "      \"glob\": \"/\"\n",
        "    }\n",
        "  }\n",
        "}\"\"\" % (BUCKET_NAME, AWS_DEFAULT_REGION, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
        "\n",
        "print(pipeline, file=open('download_from_s3.json', 'w'))"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {},
      "id": "2f5e538b-c414-4bcf-8997-aaf1cd7ff31f"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl create pipeline -f download_from_s3.json"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {},
      "id": "f650fcf8-9497-49c9-976f-1a3632727ccc"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl flush commit download_from_s3@master --raw > /dev/null 2>&1"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {},
      "id": "c2b9cb64-8fc0-4871-861f-6a22d252bf10"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl logs --pipeline=download_from_s3"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading output/xgboost-2021-08-11-09-16-18-187/output/model.tar.gz\n",
            "Downloading output/xgboost-2021-08-11-09-16-18-187/profiler-output/framework/training_job_end.ts\n",
            "Downloading output/xgboost-2021-08-11-09-16-18-187/profiler-output/system/incremental/2021081109/1628673540.algo-1.json\n",
            "Downloading output/xgboost-2021-08-11-09-16-18-187/profiler-output/system/training_job_end.ts\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {},
      "id": "1c1bf97f-26bd-45cd-9e53-d78f6b8fbe0a"
    },
    {
      "cell_type": "code",
      "source": [
        "!pachctl list file download_from_s3@master:output"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME                                    TYPE SIZE     \n",
            "/output/xgboost-2021-08-11-09-16-18-187 dir  257.5KiB \n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {},
      "id": "e016c867-40b8-444a-a58b-83ba83e41ef9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The final DAG will look like the following:\n",
        "\n",
        "![Screenshot 2021-08-09 at 16.50.58.png](attachment:23539e2a-b2e2-4d98-897d-ac973e4a52fb.png)"
      ],
      "metadata": {},
      "id": "33cc38c5-053c-4f98-9472-c3e6fe1a5811"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In this demo I have shown how to use Pachyderm and Sagemaker to train a ML model for churn prediction.\n",
        "Pachyderm is used to trigger a Sagemaker job and provide data lineage at any stage.\n",
        "Sagemaker is used to offload the training job to the cloud, all you need to do is pick the right machine type.\n",
        "This is all done in a few lines of code with the [Sagemaker Python SDK](https://sagemaker.readthedocs.io/en/stable/).\n",
        "Note that a similar workflow would apply for many other Sagemaker features such as model deployment or data processing."
      ],
      "metadata": {},
      "id": "bb486b59-9338-4671-b1d6-f31708b4d54c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}